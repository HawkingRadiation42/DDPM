# Diffusion Model Training on SYSU-Shape Dataset

This project implements a Denoising Diffusion Probabilistic Model (DDPM) to generate synthetic images based on the SYSU-Shape dataset. It utilizes the `denoising_diffusion_pytorch` library and includes custom monitoring and SLURM integration for HPC environments.

## Project Structure

- **`train.py`**: The main training script. Initializes the U-Net model, Gaussian Diffusion process, and handles the training loop with memory monitoring.
- **`run.sbatch`**: SLURM submission script for running the training job on a GPU cluster (specifically configured for A100 nodes).
- **`gpu_monitor.py`**: Custom utility to track and log GPU VRAM usage during training.
- **`plot_loss.py`**: Helper script to parse training logs and generate loss visualization plots.
- **`generate_sample.py`**: Script to generate samples from a trained model checkpoint.

## Setup

1. **Environment**:
   Ensure you have Python 3.12+ and CUDA drivers installed.
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install torch torchvision denoising_diffusion_pytorch accelerate tqdm matplotlib
   ```

2. **Dataset**:
   Place your dataset in `sysu-shape-dataset/combined/`. The training script expects images to be in this directory.

## Usage

### Running Locally
To run the training script directly (e.g., for debugging):
```bash
python train.py
```

### Running on HPC (SLURM)
Submit the job to the cluster using the provided sbatch script:
```bash
sbatch run.sbatch
```

### Monitoring
You can monitor the training progress by checking the logs:
```bash
tail -f logs/mlia.out
```
Errors will be logged to `logs/mlia.err`.

## Configuration
Key hyperparameters are defined in `train.py`:
- **Image Size**: 64x64
- **Timesteps**: 1000
- **Sampling Timesteps**: 250
- **Batch Size**: 256
- **Training Steps**: 30,000

## Outputs
- **Checkpoints & Samples**: Saved to `results_combinedV2/` (or the configured results folder).
- **Loss Plots**: Generated by running `python plot_loss.py`.
# DDPM
